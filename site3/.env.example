# Server Configuration
PORT=3000
NODE_ENV=development

# LLM Configuration
LLM_BASE_URL=http://your-llm-server:port/v1
LLM_MODEL_ID=openai/gpt-oss-120b    # Leave blank to use already loaded model on the LM Studio server


